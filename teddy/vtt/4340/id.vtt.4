WEBVTT

00:01:57.628 --> 00:02:00.750
digunakan untuk mengambil keputusan
dalam isu sosial dan politik

00:02:00.774 --> 00:02:02.465
yang fatal bagi masa depan kita?

00:02:02.995 --> 00:02:05.724
Kali ini kami mencoba mengujinya
pada konferensi TED

00:02:05.748 --> 00:02:07.291
di Vancouver, Kanada.

00:02:07.315 --> 00:02:08.522
dan inilah prosesnya.

00:02:08.546 --> 00:02:11.655
(Mariano Sigman) Kami akan memberi Anda
dua dilema moral

00:02:11.679 --> 00:02:12.853
bagi Anda di masa depan;

00:02:12.877 --> 00:02:16.279
hal-hal yang mungkin harus kita putuskan
dalam waktu dekat.

00:02:16.303 --> 00:02:20.229
Dan kami akan memberi 20 detik
untuk setiap dilema kepada Anda

00:02:20.253 --> 00:02:22.976
untuk menilai apakah dilema ini
dapat diterima atau tidak.

00:02:23.354 --> 00:02:24.859
MS: Yang pertama adalah:

00:02:24.883 --> 00:02:27.409
(Dan Ariely) Seorang peneliti 
AI (kecerdasan buatan)

00:02:27.433 --> 00:02:29.773
yang mampu meniru pikiran manusia.