WEBVTT

00:02:28.927 --> 00:02:31.912
Un : nos yeux ne peuvent pas détecter
les différences de motifs

00:02:31.912 --> 00:02:33.921
sans faire la moyenne
et éliminer le bruit.

00:02:33.921 --> 00:02:35.892
Deux : même après avoir éliminé le bruit,

00:02:35.892 --> 00:02:39.077
nos yeux ne peuvent détecter
que les signaux associés à des visages.

00:02:39.077 --> 00:02:41.509
On se tourne alors
vers l'apprentissage automatique.

00:02:41.509 --> 00:02:42.709
Nos yeux ne sont pas bons

00:02:42.709 --> 00:02:45.379
pour déceler des tendances
dans des données indémêlables,

00:02:45.379 --> 00:02:48.429
mais les algorithmes d'apprentissage
automatique sont faits pour.

00:02:48.429 --> 00:02:51.380
Pourrions-nous prendre
beaucoup d'images et de données,

00:02:51.404 --> 00:02:53.368
les introduire et entraîner un ordinateur

00:02:53.368 --> 00:02:56.599
pour qu'il puisse interpréter
ce que Christy regarde en temps réel ?

00:02:57.088 --> 00:03:01.205
Nous essayons de coder
les informations issues de son EEG