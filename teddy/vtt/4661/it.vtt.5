WEBVTT

00:02:28.704 --> 00:02:31.996
La prima: i nostri occhi non rilevano
la differenza tra modelli

00:02:31.996 --> 00:02:33.788
senza fare una media tra il rumore.

00:02:33.788 --> 00:02:36.121
La seconda: anche dopo
aver tolto il rumore

00:02:36.121 --> 00:02:38.579
possiamo solo cogliere
i segnali legati ai volti.

00:02:38.996 --> 00:02:41.163
Ci siamo dunque affidati
al <i>machine learning</i>.

00:02:41.329 --> 00:02:44.871
I nostri occhi non sanno
cogliere pattern da dati rumorosi,

00:02:45.371 --> 00:02:48.246
ma gli algoritmi delle macchine
sono progettati per questo.

00:02:48.371 --> 00:02:51.329
Quindi, possiamo prendere
molte foto e dati,

00:02:51.329 --> 00:02:53.413
inserirli e addestrare un computer

00:02:53.413 --> 00:02:56.704
per poter interpretare 
ciÃ² che Christy guarda in tempo reale?

00:02:57.246 --> 00:03:02.454
Cerchiamo di codificare le informazioni
che escono dal suo EEG in tempo reale