WEBVTT

00:03:28.888 --> 00:03:31.984
and if we're building algorithms
based on current top performers,

00:03:32.008 --> 00:03:33.224
how do we make sure

00:03:33.248 --> 00:03:36.224
that we're not just perpetuating
the biases that already exist?

00:03:36.248 --> 00:03:40.304
For example, if we were building
an algorithm based on top performing CEOs

00:03:40.328 --> 00:03:43.544
and use the S&amp;P 500 as a training set,

00:03:43.568 --> 00:03:44.824
you would actually find

00:03:44.848 --> 00:03:48.664
that you're more likely to hire
a white man named John than any woman.

00:03:48.688 --> 00:03:51.384
And that's the reality
of who's in those roles right now.

00:03:51.408 --> 00:03:54.784
But technology actually poses
a really interesting opportunity.

00:03:54.808 --> 00:03:57.064
We can create algorithms
that are more equitable

00:03:57.088 --> 00:03:59.344
and more fair than human beings
have ever been.

00:03:59.368 --> 00:04:03.064
Every algorithm that we put
into production has been pretested