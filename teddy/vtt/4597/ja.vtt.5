WEBVTT

00:02:26.106 --> 00:02:30.407
被害の最小化という設計原則から
はずれることになります

00:02:30.407 --> 00:02:35.171
そして路上において何が公正かの判断が
ロボットカーに任せられることになるのです

00:02:35.171 --> 00:02:38.403
倫理的な考慮は
さらに複雑なものになり得ます

00:02:38.403 --> 00:02:39.807
いずれのシナリオでも

00:02:39.807 --> 00:02:44.400
設計方針は目標選択アルゴリズムとして
機能しています

00:02:44.400 --> 00:02:45.299
言い換えると

00:02:45.299 --> 00:02:48.549
衝突する対象物の種類として
何を選好するか

00:02:48.549 --> 00:02:51.298
システム的に選んでいる
ということです

00:02:51.298 --> 00:02:53.893
そして標的にされた乗り物に
乗っている人は

00:02:53.893 --> 00:02:55.572
自らには過誤がない
にもかかわらず

00:02:55.572 --> 00:02:58.747
アルゴリズムの選択による負の結果を
引き受けることになります

00:02:58.747 --> 00:03:03.401
この新技術は その他にも新たな種類の
倫理的ジレンマをたくさん生み出します