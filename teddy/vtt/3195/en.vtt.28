WEBVTT

00:13:58.200 --> 00:14:01.576
Now, if you didn't like either
of those two high-tech options,

00:14:01.600 --> 00:14:04.776
it's important to remember
that low-tech is suicide

00:14:04.800 --> 00:14:06.056
from a cosmic perspective,

00:14:06.080 --> 00:14:08.576
because if we don't go far
beyond today's technology,

00:14:08.600 --> 00:14:11.416
the question isn't whether humanity
is going to go extinct,

00:14:11.440 --> 00:14:13.456
merely whether
we're going to get taken out

00:14:13.480 --> 00:14:15.616
by the next killer asteroid, supervolcano

00:14:15.640 --> 00:14:18.736
or some other problem
that better technology could have solved.

00:14:18.760 --> 00:14:22.336
So, how about having
our cake and eating it ...

00:14:22.360 --> 00:14:24.200
with AGI that's not enslaved

00:14:25.120 --> 00:14:28.296
but treats us well because its values
are aligned with ours?

00:14:28.320 --> 00:14:32.496
This is the gist of what Eliezer Yudkowsky
has called "friendly AI,"