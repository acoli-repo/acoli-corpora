WEBVTT

00:08:28.440 --> 00:08:30.656
before NASA launched
the Apollo 11 mission,

00:08:30.680 --> 00:08:33.816
they systematically thought through
everything that could go wrong

00:08:33.840 --> 00:08:36.216
when you put people
on top of explosive fuel tanks

00:08:36.240 --> 00:08:38.856
and launch them somewhere
where no one could help them.

00:08:38.880 --> 00:08:40.816
And there was a lot that could go wrong.

00:08:40.840 --> 00:08:42.320
Was that scaremongering?

00:08:43.159 --> 00:08:44.376
No.

00:08:44.400 --> 00:08:46.416
That's was precisely
the safety engineering

00:08:46.440 --> 00:08:48.376
that ensured the success of the mission,

00:08:48.400 --> 00:08:52.576
and that is precisely the strategy
I think we should take with AGI.

00:08:52.600 --> 00:08:56.656
Think through what can go wrong
to make sure it goes right.

00:08:56.680 --> 00:08:59.216
So in this spirit,
we've organized conferences,

00:08:59.240 --> 00:09:02.056
bringing together leading
AI researchers and other thinkers