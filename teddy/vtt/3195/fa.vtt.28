WEBVTT

00:13:57.930 --> 00:14:01.576
حالا اگر شما هیچ‌کدام از این دو انتخاب
برای آینده همراه با فناوری را نخواهید

00:14:01.600 --> 00:14:04.020
باید به یاد داشته باشید
که آینده با فناوری کم

00:14:04.020 --> 00:14:06.056
از منظر کیهانی همانند خودکشی است،

00:14:06.080 --> 00:14:08.470
چرا که اگر ما از مرزهای
تکنولوژی امروزی فراتر نرویم

00:14:08.470 --> 00:14:11.576
سوال این نخواهد بود
که بشریت منقرض می‌شود یا نه،

00:14:11.576 --> 00:14:13.636
بلکه اساسا درباره این خواهد بود که عامل آن

00:14:13.636 --> 00:14:15.616
سیارک قاتل بعدی است یا ابر آتشفشان

00:14:15.640 --> 00:14:18.736
یا مشکلات دیگری که می‌توانستیم
با تکنولوژی بهتر مانع‌شان شویم.

00:14:18.760 --> 00:14:21.720
خب، چطور است کیک‌مان را
داشته باشیم و آن را بخوریم ...

00:14:21.720 --> 00:14:24.590
با هوش‌مصنوعی‌همه‌جانبه‌ای در بند ما نیست

00:14:24.810 --> 00:14:28.576
بلکه با ما خوب رفتار می‌کند
چون ارزش‌های آن با ارزش‌های ما هم‌راستاست؟

00:14:28.596 --> 00:14:32.506
این نیم‌نگاهی است به آنچه که الیزر یودکاوسکی
آن‌را "هوش‌مصنوعی‌دوستانه" می‌نامد.