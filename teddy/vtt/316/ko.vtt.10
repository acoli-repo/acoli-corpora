WEBVTT

00:04:56.667 --> 00:05:00.100
(박수)

00:05:01.345 --> 00:05:04.744
제레미 하워드 : 중국에서 열린 
기계 학습 회의였습니다.

00:05:04.744 --> 00:05:07.114
학술 회의에서 실제로

00:05:07.114 --> 00:05:09.011
즉흥적인 박수를 듣기는 쉽지 않죠.

00:05:09.011 --> 00:05:12.687
그래도 TEDx 회의에서는
자유롭게 하세요.

00:05:12.687 --> 00:05:15.482
거기서 본 모든 것이
심화 학습으로 일어났습니다.

00:05:15.482 --> 00:05:17.007
(박수) 감사합니다.

00:05:17.007 --> 00:05:19.289
영어로 옮겨쓰기는 심화 학습이었죠.

00:05:19.289 --> 00:05:22.701
중국어 번역과 오른쪽 위의 글자도
심화 학습이었고

00:05:22.701 --> 00:05:26.008
목소리로 재생하는 것 역시
심화 학습이었습니다.

00:05:26.008 --> 00:05:29.242
그래서 심화 학습은 놀라운 것입니다.

00:05:29.242 --> 00:05:32.341
하나의 알고리즘인데
거의 모든 일을 할 수 있어 보입니다.