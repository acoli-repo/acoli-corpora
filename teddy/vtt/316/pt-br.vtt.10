WEBVTT

00:04:56.667 --> 00:05:00.100
(Aplausos)

00:05:01.345 --> 00:05:04.744
J. Howard: Isso foi num congresso 
de aprendizado de máquina na China.

00:05:04.744 --> 00:05:07.114
Na verdade não é comum escutar aplausos

00:05:07.114 --> 00:05:09.011
espontâneos em congressos acadêmicos,

00:05:09.011 --> 00:05:12.687
embora obviamente às vezes acontecer
em conferências TEDx, fiquem à vontade.

00:05:12.687 --> 00:05:15.482
Tudo que vocês viram lá aconteceu
com aprendizado profundo.

00:05:15.482 --> 00:05:16.927
(Aplausos) Obrigado.

00:05:16.927 --> 00:05:19.289
A transcrição em inglês foi
aprendizado profundo.

00:05:19.289 --> 00:05:22.701
A tradução para chinês e o texto na
direita superior, também,

00:05:22.701 --> 00:05:26.008
e a construção da voz também
foi aprendizado profundo.

00:05:26.008 --> 00:05:29.242
Então, aprendizado profundo é
essa coisa extraordinária.

00:05:29.242 --> 00:05:32.341
É um único algoritmo que parece
fazer quase tudo,